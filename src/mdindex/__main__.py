"""
Create index files and table of contents for collections of markdown files to
make them easier to navigate once rendered in a browser.

Index files (named <INDEX_FILE>) will be processed to include a nested list of
sibling markdown files and subdirectories (up to <MAX_DEPTH>). If the file
doesn't exist it will be created with some basic structure, otherwise this looks
for a section delimited by `<!-- mdindex:index:start -->` and `<!--
mdindex:index:start -->` to replace.

--check can be used for dry runs and validating files have been processed.
"""

from __future__ import annotations

import argparse
import fnmatch
import logging
import re
import sys
import urllib.parse
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Literal

if TYPE_CHECKING:
    from collections.abc import Iterable, Sequence


__version__ = "0.1.0"

WARNING_FILE = "<!-- WARN: This file is auto-generated. Do not edit manually. -->"
WARNING_COMMAND = "<!-- command: {command} -->"
WARNING_SECTION = "<!-- WARN: This section is auto-generated. Do not edit manually. -->"

INDEX_START_MARKER = "<!-- mdindex:index:start -->"
INDEX_END_MARKER = "<!-- mdindex:index:end -->"


logger = logging.getLogger()


class ExitError(Exception):
    def __init__(self, source: str | Exception, filepath: Path | None = None) -> None:
        super().__init__(str(source) if not filepath else f"{filepath}: {source}")


class MutlipleMarkersError(ValueError):
    def __init__(self, marker: str) -> None:
        super().__init__(f"Multiple {marker} markers found")


class ReversedMarkersError(ValueError):
    def __init__(self, from_: str, to: str) -> None:
        super().__init__(f"{to} should be after {from_}")


class SkipIndexFileError(Exception):
    def __init__(self, path: Path) -> None:
        super().__init__(f"{path} already exists and is not generated by this command")


type Action = Literal["create", "recreate", "update"]


# Lazy bag of options for less verbose passing around
@dataclass(frozen=True, slots=True)
class Context:
    index_file: str = "README.md"
    command: str | None = None
    max_depth: int = 2


@dataclass(frozen=True, slots=True)
class IndexNode:
    path: Path
    files: list[Path] = field(default_factory=list)
    children: list[IndexNode] = field(default_factory=list)


@dataclass(frozen=True, slots=True)
class Operation:
    action: Action
    path: Path
    lines: list[str]


def filter_files(directory: Path, *, ignored_globs: Sequence[str] = ()) -> Iterable[Path]:
    for x in directory.glob("**/*.md"):
        if any(fnmatch.fnmatch(str(x), pattern) for pattern in ignored_globs):
            continue
        yield x


def build_tree(directory: Path, index_file: str, files: Iterable[Path]) -> IndexNode:
    """Collect all files to consider in a basic tree structure."""
    root = IndexNode(directory)

    for x in files:
        if x.name == index_file:  # Don't include index files at this stage.
            continue

        section = root
        *parents, _ = x.relative_to(directory).parts

        for parent in parents:
            if not (child := next((x for x in section.children if x.path.name == parent), None)):
                child = IndexNode(section.path / parent)
                section.children.append(child)
            section = child

        section.files.append(x)

    return root


def get_lines(filepath: Path) -> list[str]:
    return [x.rstrip("\n") for x in filepath.open().readlines()]


def extract_title(lines: list[str]) -> tuple[int, str] | None:
    lines = list(lines)
    for i, (a, b) in enumerate(zip(lines, [*lines[1:], None])):
        if a.startswith("# "):
            return i, a[2:].strip()
        if b and re.match(r"==+", b) and (inner := a.strip()):
            return i, inner
    return None


def titlecase(value: str) -> str:
    return re.sub(r"(?<=[a-z])(?=[A-Z])|[-_]", " ", value).title()


def get_title(filepath: Path) -> str:
    if extracted := extract_title(get_lines(filepath)):
        return extracted[1]
    return titlecase(filepath.stem)


def get_section_title(path: Path, ctx: Context) -> str:
    index = path / ctx.index_file
    if index.exists() and (extracted := extract_title(get_lines(path / ctx.index_file))):
        return extracted[1]
    return titlecase(path.name)


def find_marker_line(lines: list[str], marker: str) -> int | None:
    positions = [i for i, x in enumerate(lines) if marker in x]
    if not positions:
        return None

    if len(positions) > 1:
        raise MutlipleMarkersError(marker)

    return positions[0]


def find_marked_section(lines: list[str], from_: str, to: str) -> tuple[int, int] | None:
    start = find_marker_line(lines, from_)
    end = find_marker_line(lines, to)
    if start is None or end is None:
        return None
    if end <= start:
        raise ReversedMarkersError(from_, to)
    return start, end


def render_index(section: IndexNode, ctx: Context, *, max_depth: int) -> list[str]:
    directory = section.path

    def _write_section(section: IndexNode, level: int) -> Iterable[str]:
        if level > -1:
            quoted = urllib.parse.quote(str(section.path.relative_to(directory)))
            yield f"{('  ' * level)}- [{get_section_title(section.path, ctx)}](./{quoted})"

        if (level + 1) >= max_depth:
            return

        nested = level + 1

        for x in sorted(section.files):
            title = get_title(x)
            quoted = urllib.parse.quote(str(x.relative_to(directory)))
            yield f"{('  ' * nested)}- [{title}](./{quoted})"

        for y in sorted(section.children, key=lambda x: x.path.name):
            yield from _write_section(y, nested)

    return list(_write_section(section, -1))


def render_full_index(*, name: str, inner: list[str], command: str | None = None) -> list[str]:
    return [
        INDEX_START_MARKER,
        f"# {name}",
        "",
        WARNING_FILE,
        *([f"{WARNING_COMMAND.format(command=command)}"] if command else ()),
        "",
        *inner,
        INDEX_END_MARKER,
    ]


def render_marked_index(*, inner: list[str], command: str | None = None) -> list[str]:
    return [
        INDEX_START_MARKER,
        WARNING_SECTION,
        *([f"{WARNING_COMMAND.format(command=command)}"] if command else ()),
        "",
        *inner,
        "",
        INDEX_END_MARKER,
    ]


def insert_between(lines: list[str], start: int, end: int, inner: list[str]) -> list[str]:
    before = [x for i, x in enumerate(lines) if i < start]
    after = [x for i, x in enumerate(lines) if i > end]
    if before and before[-1].strip():
        inner = ["", *inner]
    if after and after[0].strip():
        inner = [*inner, ""]
    return [*before, *inner, *after]


def index_operations(section: IndexNode, ctx: Context) -> Operation:
    index = render_index(section, ctx, max_depth=ctx.max_depth)
    output_file = section.path / ctx.index_file

    if output_file.exists():
        lines = get_lines(output_file)
        try:
            markers = find_marked_section(lines, INDEX_START_MARKER, INDEX_END_MARKER)
        except (MutlipleMarkersError, ReversedMarkersError) as e:
            raise ExitError(e, output_file) from None
        if markers is None:
            raise SkipIndexFileError(output_file)
        else:
            start, end = markers
            if start == 0:
                contents = render_full_index(
                    name=section.path.name,
                    inner=index,
                    command=ctx.command,
                )
                return Operation("recreate", output_file, contents)
            else:
                contents = insert_between(
                    lines,
                    start,
                    end,
                    render_marked_index(inner=index, command=ctx.command),
                )
                return Operation("update", output_file, contents)
    else:
        contents = render_full_index(name=section.path.name, inner=index, command=ctx.command)
        return Operation("create", output_file, contents)


def process(root: IndexNode, ctx: Context, *, recursive: bool = False) -> Iterable[Operation]:
    try:
        yield index_operations(root, ctx)
    except SkipIndexFileError as e:
        logger.debug(str(e))

    if recursive:
        for x in root.children:
            yield from process(x, ctx, recursive=recursive)


def apply(op: Operation) -> None:
    contents = "\n".join(op.lines) + "\n"
    if (not op.path.exists()) or op.path.read_text() != contents:
        logger.debug("Writing to file %s (%s)", op.path, op.action)
        op.path.write_text(contents)


def dry_run(op: Operation) -> bool:
    contents = "\n".join(op.lines) + "\n"
    logger.info("Would write to file %s (%s)", op.path, op.action)
    if (not op.path.exists()) or op.path.read_text() != contents:
        logger.info("%s is not up to date", op.path)
        return True
    return False


def main() -> None:
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument("--version", action="version", version=f"%(prog)s {__version__}")
    parser.add_argument("--verbose", "-v", help="Print debug logs to stderr", action="store_true")

    parser.add_argument("directory", type=Path, default="docs", help="Root directory")

    parser.add_argument(
        "--index-file",
        type=str,
        default="README.md",
        required=False,
        help="Index file name",
    )

    parser.add_argument(
        "--command",
        type=str,
        required=False,
        help="Command used for generating the index files",
    )

    parser.add_argument(
        "--max-depth",
        type=int,
        default=3,
        required=False,
        help="Only list files in directories up to <MAX_DEPTH> from the current index file.",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Also process subdirectories recursively.",
    )
    parser.add_argument(
        "--ignore",
        "-i",
        type=str,
        action="append",
        default=[],
        required=False,
        help=(
            "Glob patterns to ignore (repeatable). This applies to input "
            "directory and files and relies on fnmatch behaviour on the path "
            "relative to the root directory."
        ),
    )

    parser.add_argument(
        "--check",
        "-c",
        action="store_true",
        help="Check if the index files are up to date.",
    )

    args = parser.parse_args()

    logger.addHandler(logging.StreamHandler(sys.stderr))
    logger.setLevel(logging.DEBUG if args.verbose else logging.INFO)

    ctx = Context(
        index_file=args.index_file,
        command=args.command,
        max_depth=args.max_depth,
    )

    directory = Path(args.directory)

    try:
        files = filter_files(directory, ignored_globs=tuple(args.ignore))
        root = build_tree(directory, ctx.index_file, files)
        operations = process(root, ctx, recursive=args.recursive)

        if args.check:
            if any(not dry_run(op) for op in operations):
                if ctx.command:
                    logger.info("To update run: %s", ctx.command)
                sys.exit(1)
        else:
            for op in operations:
                apply(op)

    except ExitError as e:
        logger.error(e)
        sys.exit(1)


if __name__ == "__main__":
    main()
